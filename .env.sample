LLM_PROVIDER=openai # LLM provider [openai (default) / gemini / ollama / openrouter]
LLM_MODEL=gpt-5-mini # LLM 모델명 [gpt-5-mini (default) , gemini-2.5-pro, llama3, ...]
LLM_TIMEOUT_SECONDS=300 # LLM API timeout seconds [default: 300]

OPENAI_API_KEY=<your OpenAI API key> # provider=openai 인 경우 필요
GOOGLE_API_KEY=<your Google API key> # provider=gemini 인 경우 필요
OLLAMA_BASE_URL=http://localhost:11434 # provider=ollama 인 경우 필요 [default: http://localhost:11434]
OPENROUTER_API_KEY=<your OpenRouter API key> # provider=openrouter 인 경우 필요
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1 # provider=openrouter 인 경우 선택 (기본값: https://openrouter.ai/api/v1)

GITLAB_ACCESS_TOKEN=<your GitLab API token>
GITLAB_URL=https://gitlab.com
GITLAB_WEBHOOK_SECRET_TOKEN=<your expected GitLab token>

# 아래부터는 설정하지 않아도 기본값으로 동작하는 선택 옵션입니다.
REVIEW_SYSTEM_PROMPT= # (선택) 코드 리뷰용 시스템 프롬프트를 완전히 커스터마이징할 때 사용. 비워두면 기본 프롬프트 사용
REVIEW_CACHE_DB_PATH=data/review_cache.db # (선택) 리뷰 캐시 sqlite DB 파일 경로. 비워두면 data/review_cache.db 사용
LOG_LEVEL=INFO # 로그 레벨 (기본값: INFO)
ENABLE_MERGE_REQUEST_REVIEW=true # merge_request 리뷰 활성화 (기본값: true)
ENABLE_PUSH_REVIEW=true # push 리뷰 활성화 (기본값: true)
REVIEW_MAX_REQUESTS_PER_MINUTE=2 # 분당 시작 가능한 리뷰 작업 수 (기본값: 2)
REVIEW_WORKER_CONCURRENCY=1 # 리뷰 작업을 처리할 워커 스레드 개수 (기본값: 1)
REVIEW_MAX_PENDING_JOBS=100 # 경고용 대기열 길이 soft limit (기본값: 100)

# 통합 테스트(pytest)용 GitLab 설정 (옵션)
# 실제 GitLab 인스턴스에 대해 tests/test_gitlab_client_env.py 를 실행할 때만 설정하세요.
# GITLAB_TEST_PROJECT_ID=<numeric project id for integration tests>
# GITLAB_TEST_MERGE_REQUEST_IID=<merge request iid for integration tests>
# GITLAB_TEST_COMMIT_ID=<commit sha for integration tests>